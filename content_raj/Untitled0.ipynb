{
 "metadata": {
  "name": "",
  "signature": "sha256:a6afa6fe3fbad3cf59a8efb7726d28e762abc7739c9358e6166a2914f331972f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
      "#         Olivier Grisel <olivier.grisel@ensta.org>\n",
      "#         Mathieu Blondel <mathieu@mblondel.org>\n",
      "#         Lars Buitinck <L.J.Buitinck@uva.nl>\n",
      "# License: BSD 3 clause\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "import logging\n",
      "import numpy as np\n",
      "from optparse import OptionParser\n",
      "import sys\n",
      "from time import time\n",
      "import pylab as pl\n",
      "\n",
      "from sklearn.datasets import fetch_20newsgroups\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.feature_extraction.text import HashingVectorizer\n",
      "from sklearn.feature_selection import SelectKBest, chi2\n",
      "from sklearn.linear_model import RidgeClassifier\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn.linear_model import Perceptron\n",
      "from sklearn.linear_model import PassiveAggressiveClassifier\n",
      "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.neighbors import NearestCentroid\n",
      "from sklearn.utils.extmath import density\n",
      "from sklearn import metrics\n",
      "\n",
      "\n",
      "# Display progress logs on stdout\n",
      "logging.basicConfig(level=logging.INFO,\n",
      "                    format='%(asctime)s %(levelname)s %(message)s')\n",
      "\n",
      "\n",
      "# parse commandline arguments\n",
      "op = OptionParser()\n",
      "op.add_option(\"--report\",\n",
      "              action=\"store_true\", dest=\"print_report\",\n",
      "              help=\"Print a detailed classification report.\")\n",
      "op.add_option(\"--chi2_select\",\n",
      "              action=\"store\", type=\"int\", dest=\"select_chi2\",\n",
      "              help=\"Select some number of features using a chi-squared test\")\n",
      "op.add_option(\"--confusion_matrix\",\n",
      "              action=\"store_true\", dest=\"print_cm\",\n",
      "              help=\"Print the confusion matrix.\")\n",
      "op.add_option(\"--top10\",\n",
      "              action=\"store_true\", dest=\"print_top10\",\n",
      "              help=\"Print ten most discriminative terms per class\"\n",
      "                   \" for every classifier.\")\n",
      "op.add_option(\"--all_categories\",\n",
      "              action=\"store_true\", dest=\"all_categories\",\n",
      "              help=\"Whether to use all categories or not.\")\n",
      "op.add_option(\"--use_hashing\",\n",
      "              action=\"store_true\",\n",
      "              help=\"Use a hashing vectorizer.\")\n",
      "op.add_option(\"--n_features\",\n",
      "              action=\"store\", type=int, default=2 ** 16,\n",
      "              help=\"n_features when using the hashing vectorizer.\")\n",
      "op.add_option(\"--filtered\",\n",
      "              action=\"store_true\",\n",
      "              help=\"Remove newsgroup information that is easily overfit: \"\n",
      "                   \"headers, signatures, and quoting.\")\n",
      "\n",
      "(opts, args) = op.parse_args()\n",
      "if len(args) > 0:\n",
      "    op.error(\"this script takes no arguments.\")\n",
      "    sys.exit(1)\n",
      "\n",
      "print(__doc__)\n",
      "op.print_help()\n",
      "print()\n",
      "\n",
      "\n",
      "###############################################################################\n",
      "# Load some categories from the training set\n",
      "if opts.all_categories:\n",
      "    categories = None\n",
      "else:\n",
      "    categories = [\n",
      "        'alt.atheism',\n",
      "        'talk.religion.misc',\n",
      "        'comp.graphics',\n",
      "        'sci.space',\n",
      "    ]\n",
      "\n",
      "if opts.filtered:\n",
      "    remove = ('headers', 'footers', 'quotes')\n",
      "else:\n",
      "    remove = ()\n",
      "\n",
      "print(\"Loading 20 newsgroups dataset for categories:\")\n",
      "print(categories if categories else \"all\")\n",
      "\n",
      "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
      "                                shuffle=True, random_state=42,\n",
      "                                remove=remove)\n",
      "\n",
      "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
      "                               shuffle=True, random_state=42,\n",
      "                               remove=remove)\n",
      "print('data loaded')\n",
      "\n",
      "categories = data_train.target_names    # for case categories == None\n",
      "\n",
      "\n",
      "def size_mb(docs):\n",
      "    return sum(len(s.encode('utf-8')) for s in docs) / 1e6\n",
      "\n",
      "data_train_size_mb = size_mb(data_train.data)\n",
      "data_test_size_mb = size_mb(data_test.data)\n",
      "\n",
      "print(\"%d documents - %0.3fMB (training set)\" % (\n",
      "    len(data_train.data), data_train_size_mb))\n",
      "print(\"%d documents - %0.3fMB (test set)\" % (\n",
      "    len(data_test.data), data_test_size_mb))\n",
      "print(\"%d categories\" % len(categories))\n",
      "print()\n",
      "\n",
      "# split a training set and a test set\n",
      "y_train, y_test = data_train.target, data_test.target\n",
      "\n",
      "print(\"Extracting features from the training dataset using a sparse vectorizer\")\n",
      "t0 = time()\n",
      "if opts.use_hashing:\n",
      "    vectorizer = HashingVectorizer(stop_words='english', non_negative=True,\n",
      "                                   n_features=opts.n_features)\n",
      "    X_train = vectorizer.transform(data_train.data)\n",
      "else:\n",
      "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
      "                                 stop_words='english')\n",
      "    X_train = vectorizer.fit_transform(data_train.data)\n",
      "duration = time() - t0\n",
      "print(\"done in %fs at %0.3fMB/s\" % (duration, data_train_size_mb / duration))\n",
      "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
      "print()\n",
      "\n",
      "print(\"Extracting features from the test dataset using the same vectorizer\")\n",
      "t0 = time()\n",
      "X_test = vectorizer.transform(data_test.data)\n",
      "duration = time() - t0\n",
      "print(\"done in %fs at %0.3fMB/s\" % (duration, data_test_size_mb / duration))\n",
      "print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
      "print()\n",
      "\n",
      "if opts.select_chi2:\n",
      "    print(\"Extracting %d best features by a chi-squared test\" %\n",
      "          opts.select_chi2)\n",
      "    t0 = time()\n",
      "    ch2 = SelectKBest(chi2, k=opts.select_chi2)\n",
      "    X_train = ch2.fit_transform(X_train, y_train)\n",
      "    X_test = ch2.transform(X_test)\n",
      "    print(\"done in %fs\" % (time() - t0))\n",
      "    print()\n",
      "\n",
      "\n",
      "def trim(s):\n",
      "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
      "    return s if len(s) <= 80 else s[:77] + \"...\"\n",
      "\n",
      "\n",
      "# mapping from integer feature name to original token string\n",
      "if opts.use_hashing:\n",
      "    feature_names = None\n",
      "else:\n",
      "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
      "\n",
      "\n",
      "###############################################################################\n",
      "# Benchmark classifiers\n",
      "def benchmark(clf):\n",
      "    print('_' * 80)\n",
      "    print(\"Training: \")\n",
      "    print(clf)\n",
      "    t0 = time()\n",
      "    clf.fit(X_train, y_train)\n",
      "    train_time = time() - t0\n",
      "    print(\"train time: %0.3fs\" % train_time)\n",
      "\n",
      "    t0 = time()\n",
      "    pred = clf.predict(X_test)\n",
      "    test_time = time() - t0\n",
      "    print(\"test time:  %0.3fs\" % test_time)\n",
      "\n",
      "    score = metrics.f1_score(y_test, pred)\n",
      "    print(\"f1-score:   %0.3f\" % score)\n",
      "\n",
      "    if hasattr(clf, 'coef_'):\n",
      "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
      "        print(\"density: %f\" % density(clf.coef_))\n",
      "\n",
      "        if opts.print_top10 and feature_names is not None:\n",
      "            print(\"top 10 keywords per class:\")\n",
      "            for i, category in enumerate(categories):\n",
      "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
      "                print(trim(\"%s: %s\"\n",
      "                      % (category, \" \".join(feature_names[top10]))))\n",
      "        print()\n",
      "\n",
      "    if opts.print_report:\n",
      "        print(\"classification report:\")\n",
      "        print(metrics.classification_report(y_test, pred,\n",
      "                                            target_names=categories))\n",
      "\n",
      "    if opts.print_cm:\n",
      "        print(\"confusion matrix:\")\n",
      "        print(metrics.confusion_matrix(y_test, pred))\n",
      "\n",
      "    print()\n",
      "    clf_descr = str(clf).split('(')[0]\n",
      "    return clf_descr, score, train_time, test_time\n",
      "\n",
      "\n",
      "results = []\n",
      "for clf, name in (\n",
      "        (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
      "        (Perceptron(n_iter=50), \"Perceptron\"),\n",
      "        (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n",
      "        (KNeighborsClassifier(n_neighbors=10), \"kNN\")):\n",
      "    print('=' * 80)\n",
      "    print(name)\n",
      "    results.append(benchmark(clf))\n",
      "\n",
      "for penalty in [\"l2\", \"l1\"]:\n",
      "    print('=' * 80)\n",
      "    print(\"%s penalty\" % penalty.upper())\n",
      "    # Train Liblinear model\n",
      "    results.append(benchmark(LinearSVC(loss='l2', penalty=penalty,\n",
      "                                            dual=False, tol=1e-3)))\n",
      "\n",
      "    # Train SGD model\n",
      "    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
      "                                           penalty=penalty)))\n",
      "\n",
      "# Train SGD with Elastic Net penalty\n",
      "print('=' * 80)\n",
      "print(\"Elastic-Net penalty\")\n",
      "results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
      "                                       penalty=\"elasticnet\")))\n",
      "\n",
      "# Train NearestCentroid without threshold\n",
      "print('=' * 80)\n",
      "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
      "results.append(benchmark(NearestCentroid()))\n",
      "\n",
      "# Train sparse Naive Bayes classifiers\n",
      "print('=' * 80)\n",
      "print(\"Naive Bayes\")\n",
      "results.append(benchmark(MultinomialNB(alpha=.01)))\n",
      "results.append(benchmark(BernoulliNB(alpha=.01)))\n",
      "\n",
      "\n",
      "class L1LinearSVC(LinearSVC):\n",
      "\n",
      "    def fit(self, X, y):\n",
      "        # The smaller C, the stronger the regularization.\n",
      "        # The more regularization, the more sparsity.\n",
      "        self.transformer_ = LinearSVC(penalty=\"l1\",\n",
      "                                      dual=False, tol=1e-3)\n",
      "        X = self.transformer_.fit_transform(X, y)\n",
      "        return LinearSVC.fit(self, X, y)\n",
      "\n",
      "    def predict(self, X):\n",
      "        X = self.transformer_.transform(X)\n",
      "        return LinearSVC.predict(self, X)\n",
      "\n",
      "print('=' * 80)\n",
      "print(\"LinearSVC with L1-based feature selection\")\n",
      "results.append(benchmark(L1LinearSVC()))\n",
      "\n",
      "\n",
      "# make some plots\n",
      "\n",
      "indices = np.arange(len(results))\n",
      "\n",
      "results = [[x[i] for x in results] for i in range(4)]\n",
      "\n",
      "clf_names, score, training_time, test_time = results\n",
      "training_time = np.array(training_time) / np.max(training_time)\n",
      "test_time = np.array(test_time) / np.max(test_time)\n",
      "\n",
      "pl.figure(figsize=(12,8))\n",
      "pl.title(\"Score\")\n",
      "pl.barh(indices, score, .2, label=\"score\", color='r')\n",
      "pl.barh(indices + .3, training_time, .2, label=\"training time\", color='g')\n",
      "pl.barh(indices + .6, test_time, .2, label=\"test time\", color='b')\n",
      "pl.yticks(())\n",
      "pl.legend(loc='best')\n",
      "pl.subplots_adjust(left=.25)\n",
      "pl.subplots_adjust(top=.95)\n",
      "pl.subplots_adjust(bottom=.05)\n",
      "\n",
      "for i, c in zip(indices, clf_names):\n",
      "    pl.text(-.3, i, c)\n",
      "\n",
      "pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Usage: -c [options]\n",
        "\n",
        "-c: error: no such option: -f\n"
       ]
      },
      {
       "ename": "SystemExit",
       "evalue": "2",
       "output_type": "pyerr",
       "traceback": [
        "An exception has occurred, use %tb to see the full traceback.\n",
        "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "To exit: use 'exit', 'quit', or Ctrl-D.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%tb"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SystemExit",
       "evalue": "2",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-1-f01021a6ed95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m                    \"headers, signatures, and quoting.\")\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"this script takes no arguments.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/Cellar/python/2.7.6/Frameworks/Python.framework/Versions/2.7/lib/python2.7/optparse.pyc\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args, values)\u001b[0m\n\u001b[1;32m   1399\u001b[0m             \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBadOptionError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptionValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlargs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/Cellar/python/2.7.6/Frameworks/Python.framework/Versions/2.7/lib/python2.7/optparse.pyc\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m   1581\u001b[0m         \"\"\"\n\u001b[1;32m   1582\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1583\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%s: error: %s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_prog_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1585\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/Cellar/python/2.7.6/Frameworks/Python.framework/Versions/2.7/lib/python2.7/optparse.pyc\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, status, msg)\u001b[0m\n\u001b[1;32m   1571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mSystemExit\u001b[0m: 2"
       ]
      }
     ],
     "prompt_number": 2
    }
   ],
   "metadata": {}
  }
 ]
}